{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def load_embeddings(cache_file, dataset):\n",
    "    \"\"\"\n",
    "    Loads the embeddings from a file\n",
    "    \"\"\"\n",
    "    save_dict = torch.load(cache_file)\n",
    "    train_features, train_labels, train_groups, train_domains, train_filenames = save_dict['train_features'], save_dict['train_labels'], save_dict['train_groups'], save_dict['train_domains'], save_dict['train_filenames']\n",
    "    val_features, val_labels, val_groups, val_domains, val_filenames = save_dict['val_features'], save_dict['val_labels'], save_dict['val_groups'], save_dict['val_domains'], save_dict['val_filenames']\n",
    "    test_features, test_labels, test_groups, test_domains, test_filenames = save_dict['test_features'], save_dict['test_labels'], save_dict['test_groups'], save_dict['test_domains'], save_dict['test_filenames']\n",
    "    return train_features, train_labels, train_groups, train_domains, train_filenames, val_features, val_labels, val_groups, val_domains, val_filenames, test_features, test_labels, test_groups, test_domains, test_filenames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_file = \"embeddings/CUB/clip_openai_ViT-L_14.pt\"\n",
    "dataset = \"CUB\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, train_labels, train_groups, train_domains, train_filenames, val_features, val_labels, val_groups, val_domains, val_filenames, test_features, test_labels, test_groups, test_domains, test_filenames = load_embeddings(cache_file, dataset)\n",
    "\n",
    "save_dict = torch.load(cache_file)\n",
    "test_features_short = test_features[32:]\n",
    "test_domains_short = test_domains[32:]\n",
    "print(\"shape of test_features:\",test_features.shape)\n",
    "# print(test_features)\n",
    "# print(test_labels)\n",
    "print(\"len of test labels:\",len(test_labels))\n",
    "print(test_labels)\n",
    "print(test_groups)\n",
    "print(test_domains)\n",
    "#print(test_filenames)\n",
    "# for item in test_filenames:\n",
    "#     print(item)\n",
    "num_zeros = list(test_domains).count(0)\n",
    "num_ones = list(test_domains).count(1)\n",
    "print(\"Number of ones:\", num_ones)\n",
    "print(\"Number of zeros:\", num_zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def test_process(test_val,few_target_domain_index):\n",
    "    target_domain_val,source_domain_val = test_val[:3047],test_val[3047:]\n",
    "    few_target_domain_val = np.take(target_domain_val, few_target_domain_index, axis=0)\n",
    "    new_target_domain_val = np.delete(target_domain_val, few_target_domain_index, axis=0)\n",
    "    new_test_val = np.concatenate((new_target_domain_val,source_domain_val),axis=0)\n",
    "    return few_target_domain_val,new_test_val\n",
    "\n",
    "def get_few_target_domain_index(test_labels):\n",
    "    test_labels = test_labels[:3047]\n",
    "    num_classes = len(set(test_labels))\n",
    "    few_target_domain_index = []\n",
    "    for i in range(num_classes):\n",
    "        class_index = np.where(test_labels == i)[0]\n",
    "        if len(class_index) > 0:\n",
    "            few_target_domain_index.append(class_index[0])\n",
    "    return few_target_domain_index\n",
    "\n",
    "few_target_domain_index = get_few_target_domain_index(test_labels)\n",
    "print(few_target_domain_index)\n",
    "few_target_test_features,_ = test_process(test_features,few_target_domain_index)\n",
    "print(few_target_test_features[199])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "folder_path = './data/CUB-200-Painting'\n",
    "total_count = 0\n",
    "category_counts = {}\n",
    "\n",
    "category_with_10plus_count = 0\n",
    "\n",
    "for category_folder in glob.glob(os.path.join(folder_path, '*')):\n",
    "    # 确保当前文件路径是一个文件夹\n",
    "    if not os.path.isdir(category_folder):\n",
    "        continue\n",
    "    \n",
    "    category_name = os.path.basename(category_folder)\n",
    "    category_path = os.path.join(folder_path, category_name)\n",
    "    \n",
    "    image_count = len(glob.glob(os.path.join(category_path, '*.jpg')))\n",
    "    \n",
    "    total_count += image_count\n",
    "    category_counts[category_name] = image_count\n",
    "    \n",
    "    # 统计大于5张照片的类别文件夹个数\n",
    "    if image_count > 5:\n",
    "        category_with_10plus_count += 1\n",
    "\n",
    "print(\"总图片数量:\", total_count)\n",
    "print(\"每个类别文件夹的图片数量:\")\n",
    "for category_name, image_count in category_counts.items():\n",
    "    print(category_name, \":\", image_count)\n",
    "\n",
    "print(\"大于5张照片的类别文件夹个数:\", category_with_10plus_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "source_folder = \"./data/CUB-200-Painting\"\n",
    "target_folder = \"./data/CUB-Few-Painting\"\n",
    "\n",
    "os.makedirs(target_folder, exist_ok=True)\n",
    "\n",
    "subfolders = [f.path for f in os.scandir(source_folder) if f.is_dir()]\n",
    "\n",
    "for subfolder in subfolders:\n",
    "    folder_name = os.path.basename(subfolder)\n",
    "    \n",
    "    target_subfolder = os.path.join(target_folder, folder_name)\n",
    "    os.makedirs(target_subfolder, exist_ok=True)\n",
    "    \n",
    "    image_files = [f.path for f in os.scandir(subfolder) if f.is_file() and f.name.endswith(\".jpg\")]\n",
    "    \n",
    "    if image_files:\n",
    "        first_image = sorted(image_files)[0]\n",
    "        target_image = os.path.join(target_subfolder, os.path.basename(first_image))\n",
    "        shutil.copy(first_image, target_image)\n",
    "\n",
    "print(\"success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from PIL import Image\n",
    "\n",
    "def luma_transform(input):\n",
    "    assert input.shape[0] == 3, \"Input must have 3 channels\"\n",
    "    R, G, B = input[0, :, :], input[1, :, :], input[2, :, :]\n",
    "    L = R * 0.299 + G * 0.587 + B * 0.114\n",
    "    L = L.unsqueeze(0).expand(3, -1, -1)\n",
    "    return L\n",
    "\n",
    "class Cub2011Painting(torchvision.datasets.ImageFolder):\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path, target = self.samples[idx]\n",
    "\n",
    "        img =  Image.open(path)\n",
    "\n",
    "        img = img.resize((512,512), Image.ANTIALIAS)\n",
    "        img = np.array(img) / 255\n",
    "        img = torch.from_numpy(img).type(torch.FloatTensor).permute(2,0,1)\n",
    "        print(img.shape)\n",
    "        img = (img - 0.5) * 2\n",
    "\n",
    "        img = luma_transform(img)\n",
    "        print(img.shape)\n",
    "\n",
    "        return {\n",
    "            \"image\": img,\n",
    "            \"label\": target,\n",
    "            \"filename\": path,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# Load the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# construct data loader\n",
    "testset = Cub2011Painting('./data/CUB-Few-Painting', transform=None)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=1, shuffle=False)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for step,batch in enumerate(test_loader):\n",
    "        #print(step)\n",
    "        image,label,filename = batch['image'],batch['label'],batch['filename']\n",
    "        print(image.shape)\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2023-11-12 test calcuate gray image embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import clip\n",
    "import numpy as np\n",
    "import random\n",
    "from datasets.cub import Cub2011Painting\n",
    "from clip_utils import get_features\n",
    "\n",
    "# seed\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "# Load the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "clip_model, preprocess = clip.load(\"ViT-L/14\", device)\n",
    "model, preprocess = clip.load(\"ViT-L/14\", device)\n",
    "\n",
    "# construct data loader\n",
    "dataset = Cub2011Painting('./data/CUB-RemovedStyle-Painting', transform=preprocess)\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=256, shuffle=False)\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for step,batch in enumerate(loader):\n",
    "#         #print(step)\n",
    "#         print(batch['label'], batch['group'], batch['domain'], batch['filename'])\n",
    "#         break\n",
    "\n",
    "features, labels, groups, domains, filenames = get_features(loader, model, device, model_type='clip')\n",
    "\n",
    "save_dict = {\n",
    "        \"removed_style_features\": features, \"removed_style_labels\": labels, \"removed_style_groups\": groups, \"removed_style_domains\": domains, \"removed_style_filenames\": filenames,\n",
    "        \"seed\": 0\n",
    "    }\n",
    "\n",
    "cache_file = './embeddings/CUB/clip_openai_Vit-L_14_remove_style.pt'\n",
    "torch.save(save_dict, cache_file)\n",
    "print(f\"Saved CLIP embeddings to {cache_file}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dict = torch.load(cache_file)\n",
    "print(save_dict['removed_style_features'][199])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test L1 loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 创建一个L1Loss对象\n",
    "l1_loss = nn.L1Loss()\n",
    "\n",
    "# 创建两个张量作为示例输入\n",
    "input1 = torch.tensor([1, 2, 3], dtype=torch.float32)\n",
    "input2 = torch.tensor([2, 4, 6], dtype=torch.float32)\n",
    "\n",
    "# 计算L1损失\n",
    "loss = l1_loss(input1, input2)\n",
    "\n",
    "print(loss)  # 输出损失值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    x = trial.suggest_uniform('x', -10, 10)\n",
    "    y = trial.suggest_uniform('y', -10, 10)\n",
    "    return (x + y) ** 2\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "print(study.best_params)\n",
    "print(study.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test BLIP2 Caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "\n",
    "image = Image.open(\"./data/CUB-200-Painting/004.Groove_billed_Ani/Groove_billed_Ani_0.jpg\").convert('RGB')\n",
    "# url = 'https://media.newyorker.com/cartoons/63dc6847be24a6a76d90eb99/master/w_1160,c_limit/230213_a26611_838.jpg'\n",
    "# image = Image.open(requests.get(url, stream=True).raw).convert('RGB')  \n",
    "display(image.resize((596, 437)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor, Blip2ForConditionalGeneration\n",
    "import torch\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"./blip2-opt-2.7b\")\n",
    "model = Blip2ForConditionalGeneration.from_pretrained(\"./blip2-opt-2.7b\", torch_dtype=torch.float16)\n",
    "\n",
    "print(\"success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:3\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "\n",
    "prompt = \"a painting of\"\n",
    "\n",
    "inputs = processor(image, text=prompt, return_tensors=\"pt\").to(device, torch.float16)\n",
    "\n",
    "generated_ids = model.generate(**inputs, max_new_tokens=100)\n",
    "generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0].strip()\n",
    "print(prompt +\" \"+generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import requests\n",
    "from PIL import Image\n",
    "from transformers import AutoProcessor, Blip2ForConditionalGeneration\n",
    "import torch\n",
    "\n",
    "# Initialize the Blip2 model and processor\n",
    "processor = AutoProcessor.from_pretrained(\"./blip2-opt-2.7b\")\n",
    "model = Blip2ForConditionalGeneration.from_pretrained(\"./blip2-opt-2.7b\", torch_dtype=torch.float16)\n",
    "\n",
    "device = \"cuda:3\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "\n",
    "# Define the prompt\n",
    "prompt = \"a painting of\"\n",
    "\n",
    "# List of image paths\n",
    "image_paths = []\n",
    "\n",
    "directory = \"./data/CUB-200-Painting\"\n",
    "\n",
    "for root, dirs, files in os.walk(directory):\n",
    "    for file in files:\n",
    "        if file.endswith(\".jpg\") or file.endswith(\".png\"):\n",
    "            image_path = os.path.join(root, file)\n",
    "            image_paths.append(image_path)\n",
    "\n",
    "image_paths = sorted(image_paths)\n",
    "\n",
    "# CSV file path to store the results\n",
    "csv_file = \"./data/CUB-200-Painting/image_captions.csv\"\n",
    "\n",
    "# Create a list to store the image paths and captions\n",
    "image_captions = []\n",
    "\n",
    "# Process each image and generate captions\n",
    "for image_path in image_paths:\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    inputs = processor(image, text=prompt, return_tensors=\"pt\").to(device, torch.float16)\n",
    "    generated_ids = model.generate(**inputs, max_new_tokens=100)\n",
    "    generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0].strip()\n",
    "    generated_text = prompt + \" \" + generated_text\n",
    "    image_captions.append([image_path, generated_text])\n",
    "    print(\"sucess!\")\n",
    "\n",
    "# Write the image paths and captions to the CSV file\n",
    "with open(csv_file, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Image Path', 'Caption'])\n",
    "    writer.writerows(image_captions)\n",
    "\n",
    "print(\"Image captions generated and saved to\", csv_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LADS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
